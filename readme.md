# 🚀 YOLOv5 TensorRT 10 高性能推理框架

**基于 TensorRT 加速的实时目标检测解决方案 | 精准、高效、易部署**

------

## 🔍 项目背景

本项目为基于 **YOLOv5 目标检测模型** 的 **工业级推理框架**，通过 NVIDIA TensorRT 深度优化实现 **10倍+推理加速**，专为需要低延迟、高吞吐量的实时检测场景设计。结合动态内存管理与 CUDA 流优化技术，可在边缘计算设备上实现 **毫秒级图像处理**，广泛应用于安防监控、工业质检、自动驾驶等领域。

------

## 🌟 核心亮点

### ⚡ 极致性能优化

- 全链路 TensorRT 加速引擎
- 动态形状适配与显存池化技术
- 异步 CUDA 流并行处理

### 🎯 精准检测能力

- 自适应图像预处理 (LetterBox + 归一化)
- 改进型非极大值抑制 (Cluster-NMS)
- 智能坐标缩放与越界保护

### 🛠️ 工程化设计

- 上下文感知的 CUDA 资源管理
- 完善的日志追踪系统
- 显存泄漏防御机制

------

## 📦 环境依赖

| 组件         | 版本要求 |
| :----------- | :------- | 
| Python       | 3.9.18     |
| TensorRT     | 10.0.1   |
| PyCUDA       | 2023.1+  | 
| OpenCV       | 4.7.0+   |
| NumPy        | 1.24+    |
| CUDA Toolkit | 12.2    |


------

## ⚙️ 核心参数配置

| 参数                 | 类型  | 默认值    | 说明                        |
| :------------------- | :---- | :-------- | :-------------------------- |
| `conf_thres`         | float | 0.5       | 置信度阈值 (过滤低质量预测) |
| `iou_thres`          | float | 0.45      | IoU 阈值 (控制NMS聚合程度)  |
| `input_shape`        | tuple | (640,640) | 模型输入尺寸 (H,W)          |
| `dynamic_allocation` | bool  | True      | 启用动态内存分配模式        |

------

## 🚨 重要注意事项

1. **动态形状支持**
   需确保 TensorRT 引擎编译时启用 `--dynamic` 选项
2. **显存管理**
   建议为每 GPU 卡创建独立的上下文处理器
3. **CUDA 流同步**
   多线程环境下需绑定不同的 CUDA 流
4. **FP16/INT8 优化**
   量化前建议进行校准集统计 (见 `calibrate.py`)

------

## 🛠️ 开发路线图

- 视频流实时处理支持

- 多类别标签映射系统

- TensorRT 原生插件集成

- 分布式推理能力

  
